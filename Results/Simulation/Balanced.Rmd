---
title: "Balanced Result"
author: "Jianhui Gao"
date: "2023-06-06"
output: pdf_document
---

```{r setup, include=FALSE}
library(kableExtra)
library(dplyr)
library(ggplot2)
library(ggpattern)
library(tidyr)
library(Infairness)
library(pROC)
library(gridExtra)
library(SpecsVerification)
library(ggpubr)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

\newcommand{\tpr}{\mathrm{TPR}}
\newcommand{\dtpr}{\Delta_{\tpr}}

We conduct extensive simulation studies to evaluate the performance of the proposed SSL procedures and compare to supervised methods. Throughout, We generated a $p + 1 = 10 + 1$ dimensional covariates $\boldsymbol{X}$ where the first column is 1, and the remaining p columns are generated from a multivariate normal distribution $N(\boldsymbol{0}, \Sigma)$, where $\Sigma = 3 * C_{kl} = 3*(0.4)^{|k-l|}$ is a first order autoregressive correlation (AR(1)) matrix. 
We generated $A$ from a Bernoulli distribution with probability $p = 0.5$. We fit a logistic regression on $Y$ from an artificial neural network with the following model:

\begin{enumerate}
\item \textbf{Correct Model:}

$$
P(Y=1\mid \boldsymbol{X}, A) = \sigma\left\{\boldsymbol{\theta}_a^T\boldsymbol{X}\right\}I(A=a)
$$
where $\boldsymbol{\theta}_0 = (-2, 1, 1, 0.5, 0.5, \boldsymbol{0}_{6\times 1})^T, \boldsymbol{\theta}_1 = c(-1, 0.3,0.2, 0.2, 0.1, \boldsymbol{0}_{6\times 1})^T$.

\item  \textbf{Misspecified Input layer:}

$$
\widetilde{\boldsymbol{X}} = (\boldsymbol{X}, X_2^2, X_3^2, X_5X_6),
P(Y=1\mid \widetilde{\boldsymbol{X}}, A) = \sigma\left\{\widetilde{\boldsymbol{\theta}}_a^T\widetilde{\boldsymbol{X}}\right\}I(A=a)
$$

where $\widetilde{\boldsymbol{\theta}}_0 = -2.7, 1.5, 1.5, 0.5, 0.5, \boldsymbol{0}_{6\times 1}), \widetilde{\boldsymbol{\theta}}_1 = c(-1.8, 0.5,0.5, 0.5, 0.1, \boldsymbol{0}_{6\times 1})^T$.


\item \textbf{Misspecified Activation function:}
$$
P(Y=1\mid \boldsymbol{X}, A) = \exp\left\{-\left(\boldsymbol{\theta}_a^T\boldsymbol{X}\right)^2\right\}I(A=a)
$$

where $\boldsymbol{\theta}_0 = (1.4, 0.3, 0.3, 0.2, 0.2, \boldsymbol{0}_{6\times 1})^T, \boldsymbol{\theta}_1 = c( 1.3, 0.1, -0.1, 0.1, -0.1, \boldsymbol{0}_{6\times 1})^T$.

\item \textbf{Misspecified Hidden layer:}

$$
P(Y=1\mid \boldsymbol{X}, A) = \sigma\left\{2\tanh\left(\boldsymbol{\theta}_a^T\boldsymbol{X}\right)+0.3\tanh\left(\boldsymbol{\gamma}_a^T\boldsymbol{X}\right)-1\right\}I(A=a)
$$

where $\boldsymbol{\theta}_0 = -2.5, 2, 2, 1.5, 1.5, \boldsymbol{0}_{6\times 1})^T, \boldsymbol{\theta}_1 = c( -0.1, 0.25, -0.25, 0.1, 0.1, \boldsymbol{0}_{6\times 1})^T, \boldsymbol{\gamma}_0 = -1, 1, 1, 1, 1, \boldsymbol{0}_{6\times 1})^T, \boldsymbol{\gamma}_1 = c(1, 0.1, 0.1, 0.1, 0.1, \boldsymbol{0}_{6\times 1})^T$.
\end{enumerate}

The parameters of the models are chosen so that the prevalence $P(Y=1\mid A=0) \approx P(Y=1\mid A=1) = 0.3$, and the AUC in group 0 is > 0.9, in group 1 is close to 0.7. We generate an independent training dataset of size 3000, and a testing dataset of size 1000. The unlabeled dataset is 20,000.


```{r}
args = c("balanced", "correct")
if(args[1] == "balanced"){
  prev <- 0.5 # Prevalence of the protected attribute.
} else {
  prev <- 0.3 # Prevalence of the protected attribute.
}
nclass <- 2

n <- 1000 # Labeled data size.
N <- 2e4 # Unlabeled data size.

signal <- matrix(c(
  -2, 1, 1, 0.5, 0.5, rep(0, 6),
  -1, 0.3,0.2, 0.2, 0.1, rep(0, 6)
),
nrow = 2, byrow = TRUE
)

p = 10
rho = 0.4
threshold = 0.5
model <- args[2]

set.seed(1234)
indep <- DataGeneration(
  n_labeled = 50000,
  N_unlabeled = 0,
  prot_att_prevalence = prev,
  model = model,
  b0 = signal,
  b1 = b1,
  p = 10,
  rho = rho
)
# generate the main dataset
dat <- DataGeneration(
  n_labeled = n,
  N_unlabeled = N,
  prot_att_prevalence = prev,
  model = model,
  b0 = signal,
  b1 = b1,
  p = 10,
  rho = rho
)

# using indepdent data to train S
dat$S <- rep(NA, nrow(dat))
for (a in c(0,1)) {
  model_S <- glm(Y ~ .,
                 family = binomial(),
                 data = indep %>%
                   filter(A == a) %>%
                   select(-A, -Y_miss)
  )
  S <- predict(model_S, dat, type = "response")
  dat$S[dat$A == a] <- S[dat$A == a]
}


# prepare main data
dat$C <- ifelse(dat$S > threshold, 1, 0)
labeled <- dat %>% filter(!is.na(Y_miss))
unlabeled <- dat %>% filter(is.na(Y_miss))

# Calculate ROC for each group and overall
roc_overall <- roc(dat$Y, dat$S)
roc_group0 <- roc(dat$Y[dat$A==0], dat$S[dat$A==0])
roc_group1 <- roc(dat$Y[dat$A==1], dat$S[dat$A==1])

# Combine the ROC curves into a single data frame with an indicator for the group
df_overall <- data.frame(specificity = rev(roc_overall$specificities), sensitivity = roc_overall$sensitivities, group = "Overall")
df_group0 <- data.frame(specificity = rev(roc_group0$specificities), sensitivity = roc_group0$sensitivities, group = "Group 0")
df_group1 <- data.frame(specificity = rev(roc_group1$specificities), sensitivity = roc_group1$sensitivities, group = "Group 1")

df_combined <- rbind(df_overall, df_group0, df_group1)
df_combined$group <- factor(df_combined$group, levels = c("Overall", "Group 0", "Group 1"))

# Plot with ggplot2
auc_plist <- list()
auc_plist[[1]] <- ggplot(df_combined, aes(x = specificity, y = sensitivity, group = group)) + 
  geom_line() + 
  geom_abline(linetype = "dashed") +
  facet_wrap(~ group, scales = "free", ncol = 3) +
  geom_text(data = data.frame(group = factor(c("Overall", "Group 0", "Group 1"),
                                             levels = c("Overall", "Group 0", "Group 1")), 
                              x = c(0.5, 0.5, 0.5), 
                              y = c(0.2, 0.2, 0.2), 
                              label = sprintf("AUC = %.2f", c(auc(roc_overall), auc(roc_group0), auc(roc_group1)))), 
            aes(x = x, y = y, label = label), inherit.aes = FALSE) +
  labs(x = "1 - Specificity", y = "Sensitivity", title = "Correct Model") +
  theme_bw()

# Function to compute calibration data
compute_calibration_data <- function(predictions, outcomes) {
  data.frame(predictions, outcomes) %>%
    mutate(bin = cut(predictions, breaks = seq(0, 1, by = 0.1), include.lowest = TRUE)) %>%
    group_by(bin) %>%
    summarise(mean_prediction = mean(predictions),
              observed_frequency = mean(outcomes),
              .groups = 'drop')
}

# Compute calibration data for overall and each subgroup
calibration_overall <- compute_calibration_data(dat$S, dat$Y)
calibration_A0 <- compute_calibration_data(dat$S[dat$A == 0], dat$Y[dat$A == 0])
calibration_A1 <- compute_calibration_data(dat$S[dat$A == 1], dat$Y[dat$A == 1])

# Adding a group identifier
calibration_overall$group <- 'Overall'
calibration_A0$group <- 'A = 0'
calibration_A1$group <- 'A = 1'

# Combine into a single dataframe
calibration_data <- rbind(calibration_overall, calibration_A0, calibration_A1)
# Adding an "Overall" category to both datasets
calibration_data$group <- factor(calibration_data$group, levels = c("Overall", "A = 0", "A = 1"))
hist_data <- dat %>%
  mutate(group = ifelse(A == 0, "A = 0", ifelse(A == 1, "A = 1", "Overall"))) %>%
  select(S, group)
hist_data <- rbind(hist_data, data.frame(S = dat$S, group = "Overall"))

# Calibration Plot\
calibration_plist <- list()
calibration_plist[[1]] <- ggplot(calibration_data, aes(x = mean_prediction, y = observed_frequency, color = group)) +
  geom_point() +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~ group, scales = "free") +
  labs(x = "Mean Predicted Probability", y = "Observed Proportion", title = "Correct Model") +
  theme_bw() +
  theme(legend.position = "none") # Hide the legend to avoid duplication

dist_list <- list()
dist_list[[1]] <- ggplot(dat, aes(x = S)) +
  geom_histogram(aes(fill = factor(A)), bins = 30, alpha = 0.6) + # Adjust 'bins' as necessary
  facet_wrap(~ A, ncol = 1, scales = "free_y") + 
  theme_minimal() +
  labs(title = "Correct Model", x = "Predicted Probability", y = "Count")+
  theme(legend.position = "none")


args = c("balanced", "misspecified 1")

signal <- matrix(c(
  -2.7, 1.5, 1.5, 0.5, 0.5, rep(0, 6),
  -1.8, 0.5,0.5, 0.5, 0.1, rep(0, 6)
),
nrow = 2, byrow = TRUE
)

model <- args[2]

set.seed(1234)
indep <- DataGeneration(
  n_labeled = 50000,
  N_unlabeled = 0,
  prot_att_prevalence = prev,
  model = model,
  b0 = signal,
  b1 = b1,
  p = 10,
  rho = rho
)
# generate the main dataset
dat <- DataGeneration(
  n_labeled = n,
  N_unlabeled = N,
  prot_att_prevalence = prev,
  model = model,
  b0 = signal,
  b1 = b1,
  p = 10,
  rho = rho
)

# using indepdent data to train S
dat$S <- rep(NA, nrow(dat))
for (a in c(0,1)) {
  model_S <- glm(Y ~ .,
                 family = binomial(),
                 data = indep %>%
                   filter(A == a) %>%
                   select(-A, -Y_miss)
  )
  S <- predict(model_S, dat, type = "response")
  dat$S[dat$A == a] <- S[dat$A == a]
}


# prepare main data
dat$C <- ifelse(dat$S > threshold, 1, 0)
labeled <- dat %>% filter(!is.na(Y_miss))
unlabeled <- dat %>% filter(is.na(Y_miss))

# Calculate ROC for each group and overall
roc_overall <- roc(dat$Y, dat$S)
roc_group0 <- roc(dat$Y[dat$A==0], dat$S[dat$A==0])
roc_group1 <- roc(dat$Y[dat$A==1], dat$S[dat$A==1])

# Combine the ROC curves into a single data frame with an indicator for the group
df_overall <- data.frame(specificity = rev(roc_overall$specificities), sensitivity = roc_overall$sensitivities, group = "Overall")
df_group0 <- data.frame(specificity = rev(roc_group0$specificities), sensitivity = roc_group0$sensitivities, group = "Group 0")
df_group1 <- data.frame(specificity = rev(roc_group1$specificities), sensitivity = roc_group1$sensitivities, group = "Group 1")

df_combined <- rbind(df_overall, df_group0, df_group1)
df_combined$group <- factor(df_combined$group, levels = c("Overall", "Group 0", "Group 1"))
auc_plist[[2]] <- ggplot(df_combined, aes(x = specificity, y = sensitivity, group = group)) + 
  geom_line() + 
  geom_abline(linetype = "dashed") +
  facet_wrap(~ group, scales = "free", ncol = 3) +
  geom_text(data = data.frame(group = factor(c("Overall", "Group 0", "Group 1"),
                                             levels = c("Overall", "Group 0", "Group 1")), 
                              x = c(0.5, 0.5, 0.5), 
                              y = c(0.2, 0.2, 0.2), 
                              label = sprintf("AUC = %.2f", c(auc(roc_overall), auc(roc_group0), auc(roc_group1)))), 
            aes(x = x, y = y, label = label), inherit.aes = FALSE) +
  labs(x = "1 - Specificity", y = "Sensitivity", title = "Misspecified Input Layer") +
  theme_bw()

# Function to compute calibration data
compute_calibration_data <- function(predictions, outcomes) {
  data.frame(predictions, outcomes) %>%
    mutate(bin = cut(predictions, breaks = seq(0, 1, by = 0.1), include.lowest = TRUE)) %>%
    group_by(bin) %>%
    summarise(mean_prediction = mean(predictions),
              observed_frequency = mean(outcomes),
              .groups = 'drop')
}

# Compute calibration data for overall and each subgroup
calibration_overall <- compute_calibration_data(dat$S, dat$Y)
calibration_A0 <- compute_calibration_data(dat$S[dat$A == 0], dat$Y[dat$A == 0])
calibration_A1 <- compute_calibration_data(dat$S[dat$A == 1], dat$Y[dat$A == 1])

# Adding a group identifier
calibration_overall$group <- 'Overall'
calibration_A0$group <- 'A = 0'
calibration_A1$group <- 'A = 1'

# Combine into a single dataframe
calibration_data <- rbind(calibration_overall, calibration_A0, calibration_A1)
# Adding an "Overall" category to both datasets
calibration_data$group <- factor(calibration_data$group, levels = c("Overall", "A = 0", "A = 1"))
hist_data <- dat %>%
  mutate(group = ifelse(A == 0, "A = 0", ifelse(A == 1, "A = 1", "Overall"))) %>%
  select(S, group)
hist_data <- rbind(hist_data, data.frame(S = dat$S, group = "Overall"))

# Calibration Plot
calibration_plist[[2]] <- ggplot(calibration_data, aes(x = mean_prediction, y = observed_frequency, color = group)) +
  geom_point() +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~ group, scales = "free") +
  labs(x = "Mean Predicted Probability", y = "Observed Proportion", title = "Misspecified Input Layer") +
  theme_bw() +
  theme(legend.position = "none") # Hide the legend to avoid duplication
dist_list[[2]] <- ggplot(dat, aes(x = S)) +
  geom_histogram(aes(fill = factor(A)), bins = 30, alpha = 0.6) + # Adjust 'bins' as necessary
  facet_wrap(~ A, ncol = 1, scales = "free_y") + 
  theme_minimal() +
  labs(title = "Misspecified Input Layer", x = "Predicted Probability", y = "Count")+
  theme(legend.position = "none")

args = c("balanced", "misspecified 2")

signal <- matrix(c(
  1.4, 0.3, 0.3, 0.2, 0.2, rep(0, 6),
  1.1, -0.1,0.1, -0.1, 0.1, rep(0, 6)
),
nrow = 2, byrow = TRUE
)

model <- args[2]
set.seed(1234)
indep <- DataGeneration(
  n_labeled = 50000,
  N_unlabeled = 0,
  prot_att_prevalence = prev,
  model = model,
  b0 = signal,
  b1 = b1,
  p = 10,
  rho = rho
)
# generate the main dataset
dat <- DataGeneration(
  n_labeled = n,
  N_unlabeled = N,
  prot_att_prevalence = prev,
  model = model,
  b0 = signal,
  b1 = b1,
  p = 10,
  rho = rho
)

# using indepdent data to train S
dat$S <- rep(NA, nrow(dat))
for (a in c(0,1)) {
  model_S <- glm(Y ~ .,
                 family = binomial(),
                 data = indep %>%
                   filter(A == a) %>%
                   select(-A, -Y_miss)
  )
  S <- predict(model_S, dat, type = "response")
  dat$S[dat$A == a] <- S[dat$A == a]
}


# prepare main data
dat$C <- ifelse(dat$S > threshold, 1, 0)
labeled <- dat %>% filter(!is.na(Y_miss))
unlabeled <- dat %>% filter(is.na(Y_miss))

# Calculate ROC for each group and overall
roc_overall <- roc(dat$Y, dat$S)
roc_group0 <- roc(dat$Y[dat$A==0], dat$S[dat$A==0])
roc_group1 <- roc(dat$Y[dat$A==1], dat$S[dat$A==1])

# Combine the ROC curves into a single data frame with an indicator for the group
df_overall <- data.frame(specificity = rev(roc_overall$specificities), sensitivity = roc_overall$sensitivities, group = "Overall")
df_group0 <- data.frame(specificity = rev(roc_group0$specificities), sensitivity = roc_group0$sensitivities, group = "Group 0")
df_group1 <- data.frame(specificity = rev(roc_group1$specificities), sensitivity = roc_group1$sensitivities, group = "Group 1")

df_combined <- rbind(df_overall, df_group0, df_group1)
df_combined$group <- factor(df_combined$group, levels = c("Overall", "Group 0", "Group 1"))
auc_plist[[3]] <- ggplot(df_combined, aes(x = specificity, y = sensitivity, group = group)) + 
  geom_line() + 
  geom_abline(linetype = "dashed") +
  facet_wrap(~ group, scales = "free", ncol = 3) +
  geom_text(data = data.frame(group = factor(c("Overall", "Group 0", "Group 1"),
                                             levels = c("Overall", "Group 0", "Group 1")), 
                              x = c(0.5, 0.5, 0.5), 
                              y = c(0.2, 0.2, 0.2), 
                              label = sprintf("AUC = %.2f", c(auc(roc_overall), auc(roc_group0), auc(roc_group1)))), 
            aes(x = x, y = y, label = label), inherit.aes = FALSE) +
  labs(x = "1 - Specificity", y = "Sensitivity", title = "Misspecified Activation Function") +
  theme_bw()


# Function to compute calibration data
compute_calibration_data <- function(predictions, outcomes) {
  data.frame(predictions, outcomes) %>%
    mutate(bin = cut(predictions, breaks = seq(0, 1, by = 0.1), include.lowest = TRUE)) %>%
    group_by(bin) %>%
    summarise(mean_prediction = mean(predictions),
              observed_frequency = mean(outcomes),
              .groups = 'drop')
}

# Compute calibration data for overall and each subgroup
calibration_overall <- compute_calibration_data(dat$S, dat$Y)
calibration_A0 <- compute_calibration_data(dat$S[dat$A == 0], dat$Y[dat$A == 0])
calibration_A1 <- compute_calibration_data(dat$S[dat$A == 1], dat$Y[dat$A == 1])

# Adding a group identifier
calibration_overall$group <- 'Overall'
calibration_A0$group <- 'A = 0'
calibration_A1$group <- 'A = 1'

# Combine into a single dataframe
calibration_data <- rbind(calibration_overall, calibration_A0, calibration_A1)
# Adding an "Overall" category to both datasets
calibration_data$group <- factor(calibration_data$group, levels = c("Overall", "A = 0", "A = 1"))
hist_data <- dat %>%
  mutate(group = ifelse(A == 0, "A = 0", ifelse(A == 1, "A = 1", "Overall"))) %>%
  select(S, group)
hist_data <- rbind(hist_data, data.frame(S = dat$S, group = "Overall"))

# Calibration Plot
calibration_plist[[3]] <- ggplot(calibration_data, aes(x = mean_prediction, y = observed_frequency, color = group)) +
  geom_point() +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~ group, scales = "free") +
  labs(x = "Mean Predicted Probability", y = "Observed Proportion", title = "Misspecified Activation Function") +
  theme_bw() +
  theme(legend.position = "none") # Hide the legend to avoid duplication

dist_list[[3]] <- ggplot(dat, aes(x = S)) +
  geom_histogram(aes(fill = factor(A)), bins = 30, alpha = 0.6) + # Adjust 'bins' as necessary
  facet_wrap(~ A, ncol = 1, scales = "free_y") + 
  theme_minimal() +
  labs(title = "Misspecified Activation Function", x = "Predicted Probability", y = "Count") +
  theme(legend.position = "none")

args = c("balanced", "misspecified 3")
if(args[1] == "balanced"){
  prev <- 0.5 # Prevalence of the protected attribute.
} else {
  prev <- 0.7 # Prevalence of the protected attribute.
}

nclass <- 2

n <- 1000 # Labeled data size.
N <- 2e4 # Unlabeled data size.

n <- 500 * nclass # Labeled data size.
N <- 1e4 * nclass # Unlabeled data size.
signal <- matrix(c(
  -2.5, 2, 2, 1.5, 1.5, rep(0, 6),
  -0.2, 0.5, -0.5, 0.1, 0.1, rep(0, 6)
),
nrow = 2, byrow = TRUE
)

p = 10
rho = 0.4
threshold = 0.5
model <- args[2]
# generate an indepdent dataset
b1 <- matrix(c(
  -1, 1, 1, 1, 1, rep(0, 6),
  1, -0.5, 0.5, -0.2, -0.2, rep(0, 6)
),
nrow = 2, byrow = TRUE
)

set.seed(1234)
indep <- DataGeneration(
  n_labeled = 50000,
  N_unlabeled = 0,
  prot_att_prevalence = prev,
  model = model,
  b0 = signal,
  b1 = b1,
  p = 10,
  rho = rho
)
# generate the main dataset
dat <- DataGeneration(
  n_labeled = n,
  N_unlabeled = N,
  prot_att_prevalence = prev,
  model = model,
  b0 = signal,
  b1 = b1,
  p = 10,
  rho = rho
)

# using indepdent data to train S
dat$S <- rep(NA, nrow(dat))
for (a in c(0,1)) {
  model_S <- glm(Y ~ .,
                 family = binomial(),
                 data = indep %>%
                   filter(A == a) %>%
                   select(-A, -Y_miss)
  )
  S <- predict(model_S, dat, type = "response")
  dat$S[dat$A == a] <- S[dat$A == a]
}


# prepare main data
dat$C <- ifelse(dat$S > threshold, 1, 0)
labeled <- dat %>% filter(!is.na(Y_miss))
unlabeled <- dat %>% filter(is.na(Y_miss))


# Calculate ROC for each group and overall
roc_overall <- roc(dat$Y, dat$S)
roc_group0 <- roc(dat$Y[dat$A==0], dat$S[dat$A==0])
roc_group1 <- roc(dat$Y[dat$A==1], dat$S[dat$A==1])

# Combine the ROC curves into a single data frame with an indicator for the group
df_overall <- data.frame(specificity = rev(roc_overall$specificities), sensitivity = roc_overall$sensitivities, group = "Overall")
df_group0 <- data.frame(specificity = rev(roc_group0$specificities), sensitivity = roc_group0$sensitivities, group = "Group 0")
df_group1 <- data.frame(specificity = rev(roc_group1$specificities), sensitivity = roc_group1$sensitivities, group = "Group 1")

df_combined <- rbind(df_overall, df_group0, df_group1)
df_combined$group <- factor(df_combined$group, levels = c("Overall", "Group 0", "Group 1"))
auc_plist[[4]] <- ggplot(df_combined, aes(x = specificity, y = sensitivity, group = group)) + 
  geom_line() + 
  geom_abline(linetype = "dashed") +
  facet_wrap(~ group, scales = "free", ncol = 3) +
  geom_text(data = data.frame(group = factor(c("Overall", "Group 0", "Group 1"),
                                             levels = c("Overall", "Group 0", "Group 1")), 
                              x = c(0.5, 0.5, 0.5), 
                              y = c(0.2, 0.2, 0.2), 
                              label = sprintf("AUC = %.2f", c(auc(roc_overall), auc(roc_group0), auc(roc_group1)))), 
            aes(x = x, y = y, label = label), inherit.aes = FALSE) +
  labs(x = "1 - Specificity", y = "Sensitivity", title = "Misspecified Hidden Layer") +
  theme_bw()

# Function to compute calibration data
compute_calibration_data <- function(predictions, outcomes) {
  data.frame(predictions, outcomes) %>%
    mutate(bin = cut(predictions, breaks = seq(0, 1, by = 0.1), include.lowest = TRUE)) %>%
    group_by(bin) %>%
    summarise(mean_prediction = mean(predictions),
              observed_frequency = mean(outcomes),
              .groups = 'drop')
}

# Compute calibration data for overall and each subgroup
calibration_overall <- compute_calibration_data(dat$S, dat$Y)
calibration_A0 <- compute_calibration_data(dat$S[dat$A == 0], dat$Y[dat$A == 0])
calibration_A1 <- compute_calibration_data(dat$S[dat$A == 1], dat$Y[dat$A == 1])

# Adding a group identifier
calibration_overall$group <- 'Overall'
calibration_A0$group <- 'A = 0'
calibration_A1$group <- 'A = 1'

# Combine into a single dataframe
calibration_data <- rbind(calibration_overall, calibration_A0, calibration_A1)
# Adding an "Overall" category to both datasets
calibration_data$group <- factor(calibration_data$group, levels = c("Overall", "A = 0", "A = 1"))
hist_data <- dat %>%
  mutate(group = ifelse(A == 0, "A = 0", ifelse(A == 1, "A = 1", "Overall"))) %>%
  select(S, group)
hist_data <- rbind(hist_data, data.frame(S = dat$S, group = "Overall"))

# Calibration Plot
calibration_plist[[4]] <- ggplot(calibration_data, aes(x = mean_prediction, y = observed_frequency, color = group)) +
  geom_point() +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  facet_wrap(~ group, scales = "free") +
  labs(x = "Mean Predicted Probability", y = "Observed Proportion", title = "Misspecified Hidden Layer") +
  theme_bw() +
  theme(legend.position = "none") # Hide the legend to avoid duplication

dist_list[[4]] <- ggplot(dat, aes(x = S)) +
  geom_histogram(aes(fill = factor(A)), bins = 30, alpha = 0.6) + # Adjust 'bins' as necessary
  facet_wrap(~ A, ncol = 1, scales = "free_y") + 
  theme_minimal() +
  labs(title = "Misspecified Hidden Layer", x = "Predicted Probability", y = "Count") +
  theme(legend.position = "none") # Hide the legend to avoid duplication
```



# AUC curves


```{r, fig.height=10}
ggpubr::ggarrange(plotlist = auc_plist, ncol = 1)
```

# Calibration curves

```{r, fig.height=12, fig.width=9}
ggpubr::ggarrange(plotlist = calibration_plist, ncol = 1)
```

# Distribution of S

```{r, fig.height=8, fig.width=8}

ggpubr::ggarrange(plotlist = dist_list)

```

# Main Figure


```{r}
files <- list.files("Results/Simulation/", full.names = TRUE, pattern = "^balanced")
for (i in files){
  results <- readRDS(i)
  oracle_est <- do.call(rbind, lapply(results, function(ll) ll$oracle_est))  %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)
oracle_var <- do.call(rbind, lapply(results, function(ll) ll$oracle_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
oracle <- oracle_est %>% left_join(oracle_var, by = c("Metric", "Group")) %>% mutate(Method = "Oracle")

sup_est <- do.call(rbind, lapply(results, function(ll) ll$sup_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)
sup_var <- do.call(rbind, lapply(results, function(ll) ll$sup_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
sup <- sup_est %>% left_join(sup_var, by = c("Metric", "Group")) %>% mutate(Method = "Supervised")

ss_est <- do.call(rbind, lapply(results, function(ll) ll$ss_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)
ss_var <- do.call(rbind, lapply(results, function(ll) ll$ss_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
ss <- ss_est %>% left_join(ss_var, by = c("Metric", "Group")) %>% mutate(Method = "Infairness")

naive_est <- do.call(rbind, lapply(results, function(ll) ll$naive_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)

naive_var <- do.call(rbind, lapply(results, function(ll) ll$naive_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
naive <- naive_est %>% left_join(naive_var, by = c("Metric", "Group")) %>% mutate(Method = "Naive")

platt_est <- do.call(rbind, lapply(results, function(ll) ll$platt_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)

platt_var <- do.call(rbind, lapply(results, function(ll) ll$platt_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)

platt <- platt_est %>% left_join(platt_var, by = c("Metric", "Group")) %>% mutate(Method = "Platt Scaling")

beta_est <- do.call(rbind, lapply(results, function(ll) ll$beta_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)
beta_var <- do.call(rbind, lapply(results, function(ll) ll$beta_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
beta <- beta_est %>% left_join(beta_var, by = c("Metric", "Group")) %>% mutate(Method = "Beta Calibration")

rbind(oracle, sup, ss) %>% 
  filter(!Metric %in% c("FNR", "FPR")) %>%
  mutate(Method = factor(Method, levels = c("Oracle", "Supervised", "Infairness"))) %>%
  mutate(Group = factor(Group, levels = c("Group0", "Group1", "Delta"))) %>%
  ggplot(aes(x = Metric, y = Est, fill = Method)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = Est - 1.96* sqrt(Var), ymax = Est + 1.9*sqrt(Var)), position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~Group, ncol = 3) +
  theme_bw() +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1))+
  xlab("") +
  ylab("Estimated Value") +
  ggsci::scale_fill_nejm()
ggsave(paste0("Results/Simulation/pest_main_",sub(".*_(.*)\\.rds", "\\1", i), ".png"), width = 6, height = 3, dpi = 360, units = "in", device = "png")


sup <- cbind(sup[,1:2], bias = sup$Est - oracle$Est) %>%
  left_join(sup, by = c("Metric", "Group")) %>%
  mutate(MSE = bias^2 + Var)
ss <- cbind(ss[,1:2], bias = ss$Est - oracle$Est) %>%
  left_join(ss, by = c("Metric", "Group")) %>%
  mutate(MSE = bias^2 + Var)
naive <- cbind(naive[,1:2], bias = naive$Est - oracle$Est) %>%
  left_join(naive, by = c("Metric", "Group")) %>%
  mutate(MSE = bias^2 + Var)
platt <- cbind(platt[,1:2], bias = platt$Est - oracle$Est) %>%
  left_join(platt, by = c("Metric", "Group")) %>%
  mutate(MSE = bias^2 + Var)
beta <- cbind(beta[,1:2], bias = beta$Est - oracle$Est) %>%
  left_join(beta, by = c("Metric", "Group")) %>%
  mutate(MSE = bias^2 + Var)

re <- cbind(sup[,1:2], re = sup$MSE/ss$MSE, method = "Infairness")

re  %>% 
  filter(!Metric %in% c("FNR", "FPR")) %>%
    mutate(Group = factor(Group, levels = c("Group0", "Group1", "Delta"))) %>% ggplot(aes(x = Metric, y = re, fill = Group)) +
    geom_bar(stat = "identity", position = "dodge") +
    theme_bw() +
    theme(legend.position = "bottom") +
    geom_abline(intercept = 1, slope = 0, linetype = "dashed") +
    ylab("Relative Efficiency \n (Supervised:Infairness)") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "none")+
    xlab("")+
    ggsci::scale_fill_lancet()+
    ylim(0, 2.5)
ggsave(paste0("Results/Simulation/re_main_",sub(".*_(.*)\\.rds", "\\1", i), ".png"), width = 6, height = 3, dpi = 360, units = "in", device = "png")

#as_ggplot(q)
#ggsave("legened_re.png",q, width = 3, height = 1, units = "in", device = "png")

sup <- do.call(rbind, lapply(results, function(ll) ll$sup_est)) %>% group_by(Metric) %>% summarise_all(function(x) var(x, na.rm = TRUE)) %>%
  pivot_longer(cols = -c(Metric), names_to = "Group", values_to = "EVar") %>%
  left_join(sup, by = c("Metric", "Group")) %>%
  mutate(EMSE = bias^2 + EVar)
ss <- do.call(rbind, lapply(results, function(ll) ll$ss_est)) %>% group_by(Metric) %>% summarise_all(function(x) var(x, na.rm = TRUE)) %>%
  pivot_longer(cols = -c(Metric), names_to = "Group", values_to = "EVar") %>%
  left_join(ss, by = c("Metric", "Group"))%>%
  mutate(EMSE = bias^2 + EVar)

re <- cbind(sup[,1:2], re = sup$EMSE/ss$EMSE)

sup_est <- do.call(rbind, lapply(results, function(ll) ll$sup_est))
sup_var <- do.call(rbind, lapply(results, function(ll) ll$sup_var))
sup_delta_ci <- data.frame(Metric = sup_est[,1], L = sup_est$Delta - 1.96*sqrt(sup_var$Delta), U = sup_est$Delta + 1.96*sqrt(sup_var$Delta))
oracle_delta <- oracle %>% filter(Group == "Delta")
sup_delta_ci <- sup_delta_ci %>% left_join(oracle_delta, by = "Metric") %>% mutate(Coverage = ifelse(L <= Est & U >= Est, 1, 0)) %>% group_by(Metric) %>% summarise(Coverage = mean(Coverage, na.rm = TRUE)) %>% mutate(Group = "Delta")

sup_1_ci <- data.frame(Metric = sup_est[,1], L = sup_est$Group1 - 1.96*sqrt(sup_var$Group1), U = sup_est$Group1 + 1.96*sqrt(sup_var$Group1))
oracle_1<- oracle %>% filter(Group == "Group1")
sup_1_ci <- sup_1_ci %>% left_join(oracle_1, by = "Metric") %>% mutate(Coverage = ifelse(L <= Est & U >= Est, 1, 0)) %>% group_by(Metric) %>% summarise(Coverage = mean(Coverage, na.rm = TRUE)) %>% mutate(Group = "Group1")

sup_2_ci <- data.frame(Metric = sup_est[,1], L = sup_est$Group0 - 1.96*sqrt(sup_var$Group0), U = sup_est$Group0 + 1.96*sqrt(sup_var$Group0))
oracle_2<- oracle %>% filter(Group == "Group0")
sup_2_ci <- sup_2_ci %>% left_join(oracle_2, by = "Metric") %>% mutate(Coverage = ifelse(L <= Est & U >= Est, 1, 0)) %>% group_by(Metric) %>% summarise(Coverage = mean(Coverage, na.rm = TRUE)) %>% mutate(Group = "Group0")

ss_est <- do.call(rbind, lapply(results, function(ll) ll$ss_est))
ss_var <- do.call(rbind, lapply(results, function(ll) ll$ss_var))
ss_delta_ci <- data.frame(Metric = ss_est[,1], L = ss_est$Delta - 1.96*sqrt(ss_var$Delta), U = ss_est$Delta + 1.96*sqrt(ss_var$Delta))
ss_delta_ci <- ss_delta_ci %>% left_join(oracle_delta, by = "Metric") %>% mutate(Coverage = ifelse(L <= Est & U >= Est, 1, 0)) %>% group_by(Metric) %>% summarise(Coverage = mean(Coverage, na.rm = TRUE)) %>% mutate(Group = "Delta")

ss_1_ci <- data.frame(Metric = ss_est[,1], L = ss_est$Group1 - 1.96*sqrt(ss_var$Group1), U = ss_est$Group1 + 1.96*sqrt(ss_var$Group1))
ss_1_ci <- ss_1_ci %>% left_join(oracle_1, by = "Metric") %>% mutate(Coverage = ifelse(L <= Est & U >= Est, 1, 0)) %>% group_by(Metric) %>% summarise(Coverage = mean(Coverage, na.rm = TRUE)) %>% mutate(Group = "Group1")

ss_2_ci <- data.frame(Metric = ss_est[,1], L = ss_est$Group0 - 1.96*sqrt(ss_var$Group0), U = ss_est$Group0 + 1.96*sqrt(ss_var$Group0))
ss_2_ci <- ss_2_ci %>% left_join(oracle_2, by = "Metric") %>% mutate(Coverage = ifelse(L <= Est & U >= Est, 1, 0)) %>% group_by(Metric) %>% summarise(Coverage = mean(Coverage, na.rm = TRUE)) %>% mutate(Group = "Group0")

rbind(cbind(rbind(sup_1_ci, sup_2_ci, sup_delta_ci), method = "Supervised"),
      cbind(rbind(ss_1_ci, ss_2_ci, ss_delta_ci), method = "Infairness"))  %>% 
  filter(!Metric %in% c("FNR", "FPR")) %>%
    mutate(Group = factor(Group, levels = c("Group0", "Group1", "Delta")),
           method = factor(method, levels = c("Supervised", "Infairness"))) %>% ggplot(aes(x = Metric, y = Coverage, fill = method)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_bw() +
  theme(legend.position = "bottom") +
  geom_abline(intercept = 0.95, slope = 0, col = "red")+
  geom_abline(intercept = 0.9, slope = 0 , linetype = "dashed")+
  facet_wrap(~Group, ncol = 3) +
  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.9, 0.95), limits = c(0, 1))+
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "none")+
    xlab("")+
    ylab("Coverage Probability")+
    scale_fill_manual(values = c("Supervised" = pal_nejm()(3)[2], "Infairness" = pal_nejm()(3)[3]))

ggsave(paste0("Results/Simulation/cp_",sub(".*_(.*)\\.rds", "\\1", i), ".png"), width = 6, height = 3, dpi = 360, units = "in", device = "png")


}


p <- rbind(cbind(rbind(sup_1_ci, sup_2_ci, sup_delta_ci), method = "Supervised"),
      cbind(rbind(ss_1_ci, ss_2_ci, ss_delta_ci), method = "Infairness"))  %>% 
  filter(!Metric %in% c("FNR", "FPR")) %>%
    mutate(Group = factor(Group, levels = c("Group0", "Group1", "Delta")),
           method = factor(method, levels = c("Supervised", "Infairness"))) %>% ggplot(aes(x = Metric, y = Coverage, fill = method)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_bw() +
  theme(legend.position = "bottom") +
  geom_abline(intercept = 0.95, slope = 0, col = "red")+
  geom_abline(intercept = 0.9, slope = 0 , linetype = "dashed")+
  facet_wrap(~Group, ncol = 3) +
  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 0.9, 0.95), limits = c(0, 1))+
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "bottom")+
    xlab("")+
    ylab("Coverage Probability")+
    scale_fill_manual(values = c("Supervised" = pal_nejm()(3)[2], "Infairness" = pal_nejm()(3)[3]))+labs(fill = "Method")
q<- get_legend(p)
as_ggplot(q)
ggsave("Results/Simulation/cp_legend.png", q, width = 3, height = 1, units = "in", device = "png")
```

# Supplementary Figure

```{r}
files <- list.files("Results/Simulation/", full.names = TRUE, pattern = "^balanced")
for (i in files){
  results <- readRDS(i)
  oracle_est <- do.call(rbind, lapply(results, function(ll) ll$oracle_est))  %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)
oracle_var <- do.call(rbind, lapply(results, function(ll) ll$oracle_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
oracle <- oracle_est %>% left_join(oracle_var, by = c("Metric", "Group")) %>% mutate(Method = "Oracle")

sup_est <- do.call(rbind, lapply(results, function(ll) ll$sup_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)
sup_var <- do.call(rbind, lapply(results, function(ll) ll$sup_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
sup <- sup_est %>% left_join(sup_var, by = c("Metric", "Group")) %>% mutate(Method = "Supervised")

ss_est <- do.call(rbind, lapply(results, function(ll) ll$ss_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)
ss_var <- do.call(rbind, lapply(results, function(ll) ll$ss_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
ss <- ss_est %>% left_join(ss_var, by = c("Metric", "Group")) %>% mutate(Method = "Infairness")

naive_est <- do.call(rbind, lapply(results, function(ll) ll$naive_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)

naive_var <- do.call(rbind, lapply(results, function(ll) ll$naive_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
naive <- naive_est %>% left_join(naive_var, by = c("Metric", "Group")) %>% mutate(Method = "Naive")

platt_est <- do.call(rbind, lapply(results, function(ll) ll$platt_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)

platt_var <- do.call(rbind, lapply(results, function(ll) ll$platt_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)

platt <- platt_est %>% left_join(platt_var, by = c("Metric", "Group")) %>% mutate(Method = "Platt Scaling")

beta_est <- do.call(rbind, lapply(results, function(ll) ll$beta_est)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Est"
)
beta_var <- do.call(rbind, lapply(results, function(ll) ll$beta_var)) %>% group_by(Metric) %>% summarise_all(function(x) mean(x, na.rm = TRUE)) %>% pivot_longer(
  cols = -c(Metric),
  names_to = "Group",
  values_to = "Var"
)
beta <- beta_est %>% left_join(beta_var, by = c("Metric", "Group")) %>% mutate(Method = "Beta Calibration")

rbind(oracle, naive, platt, beta) %>% 
  filter(!Metric %in% c("FNR", "FPR")) %>%
  mutate(Method = factor(Method, levels = c("Oracle", "Naive", "Platt Scaling", "Beta Calibration"))) %>%
  mutate(Group = factor(Group, levels = c("Group0", "Group1", "Delta"))) %>%
  ggplot(aes(x = Metric, y = Est, fill = Method)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = Est - 1.96* sqrt(Var), ymax = Est + 1.9*sqrt(Var)), position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~Group, ncol = 3) +
  theme_bw() +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1))+
  xlab("") +
  ylab("Estimated Value") +
  scale_fill_manual(values = ggsci::pal_nejm()(6)[c(1,4,5,6)])
ggsave(paste0("Results/Simulation/pest_supp_naive",sub(".*_(.*)\\.rds", "\\1", i), ".png"), width = 6, height = 3, dpi = 360, units = "in", device = "png")

}

p <- rbind(oracle, naive, platt, beta) %>% 
    filter(!Metric %in% c("FNR", "FPR")) %>%
    mutate(Method = factor(Method, levels = c("Oracle", "Naive", "Platt Scaling", "Beta Calibration"))) %>%
    mutate(Group = factor(Group, levels = c("Group0", "Group1", "Delta"))) %>%
    ggplot(aes(x = Metric, y = Est, fill = Method)) +
    geom_bar(stat = "identity", position = "dodge") +
    geom_errorbar(aes(ymin = Est - 1.96* sqrt(Var), ymax = Est + 1.9*sqrt(Var)), position = position_dodge(width = 0.9), width = 0.25) +
    facet_wrap(~Group, ncol = 3) +
    theme_bw() +
    theme(legend.position = "bottom", 
          axis.text.x = element_text(angle = 45, hjust = 1))+
    xlab("") +
    ylab("Estimated Value") +
    scale_fill_manual(values = ggsci::pal_nejm()(6)[c(1,4,5,6)])

q<-ggpubr::get_legend(p)
as_ggplot(q)
ggsave("Results/Simulation/pest_supp_naive_legend.png", q, width = 6, height = 1, units = "in", device = "png")
```


